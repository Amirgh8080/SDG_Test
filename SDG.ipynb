{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOnxhMyPYiKqgV792Ne5IIZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amirgh8080/SDG_Test/blob/main/SDG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing the implmentation of the SDG model"
      ],
      "metadata": {
        "id": "bqiu9AHXXmdA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.Preparing the VM"
      ],
      "metadata": {
        "id": "anJSMntwZD98"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing the nessassaries libraries suggested by the paper's authors"
      ],
      "metadata": {
        "id": "bQXL1DC4X2uu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZI_etiNhQwNk",
        "outputId": "1fbc3857-a0b2-4a9e-be1d-802685b6fc40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.14.6\n",
            "  Downloading numpy-1.14.6.zip (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting scipy==1.2.1\n",
            "  Downloading scipy-1.2.1.tar.gz (23.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.1/23.1 MB\u001b[0m \u001b[31m88.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: Ignored the following versions that require a different python version: 1.6.2 Requires-Python >=3.7,<3.10; 1.6.3 Requires-Python >=3.7,<3.10; 1.7.0 Requires-Python >=3.7,<3.10; 1.7.1 Requires-Python >=3.7,<3.10\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement pytorch==1.6.0 (from versions: 0.1.2, 1.0.2)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for pytorch==1.6.0\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install numpy==1.14.6 scipy==1.2.1 pytorch==1.6.0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extracting the model files"
      ],
      "metadata": {
        "id": "0l6hV5UsYGfp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip SDG-main.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7ZuLiM8RZ4I",
        "outputId": "d6ecff99-3940-48c0-d99e-da07121112a6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  SDG-main.zip\n",
            "7a09ae77466aca8ecb68300104d6880fab295412\n",
            "   creating: SDG-main/\n",
            "  inflating: SDG-main/README.md      \n",
            "   creating: SDG-main/code/\n",
            "  inflating: SDG-main/code/README.md  \n",
            "  inflating: SDG-main/code/main.py   \n",
            "   creating: SDG-main/code/sdg/\n",
            "   creating: SDG-main/code/sdg/data/\n",
            "  inflating: SDG-main/code/sdg/data/citeseer.npz  \n",
            "  inflating: SDG-main/code/sdg/data/cora_ml.npz  \n",
            "  inflating: SDG-main/code/sdg/data/io.py  \n",
            "  inflating: SDG-main/code/sdg/data/pubmed.npz  \n",
            "  inflating: SDG-main/code/sdg/data/sparsegraph.py  \n",
            "   creating: SDG-main/code/sdg/pytorch_code/\n",
            "  inflating: SDG-main/code/sdg/pytorch_code/agnostic_model.py  \n",
            "  inflating: SDG-main/code/sdg/pytorch_code/earlystopping.py  \n",
            "  inflating: SDG-main/code/sdg/pytorch_code/preprocessing.py  \n",
            "  inflating: SDG-main/code/sdg/pytorch_code/propagation.py  \n",
            "  inflating: SDG-main/code/sdg/pytorch_code/training.py  \n",
            "  inflating: SDG-main/code/sdg/pytorch_code/utils.py  \n",
            "   creating: SDG-main/paper/\n",
            "  inflating: SDG-main/paper/SDG_A Simplified and Dynamic Graph Neural Network.pdf  \n",
            "   creating: SDG-main/slides/\n",
            "  inflating: SDG-main/slides/SIGIR'21_SDG_Presentation_Slides.pdf  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.Testing Model"
      ],
      "metadata": {
        "id": "-A8jRAIyYy4J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing the model on Cora_ML Dataset"
      ],
      "metadata": {
        "id": "XGAg097hYPH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit\n",
        "!python SDG-main/code/main.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiCHAyciRp-I",
        "outputId": "29c0b2b4-4fcb-4ffd-f9a8-563daf49295e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/SDG-main/code/sdg/pytorch_code/agnostic_model.py:22: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if drop_prob is 0:\n",
            "2024-11-27 20:22:48: agnostic_model: {'hiddenunits': [64], 'drop_prob': 0.5, 'propagation': PPRExact()}\n",
            "2024-11-27 20:22:48: PyTorch seed: 2486866278\n",
            "/content/SDG-main/code/sdg/pytorch_code/utils.py:74: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:651.)\n",
            "  return torch.sparse.FloatTensor(\n",
            "2024-11-27 20:22:52: Epoch 0: Train loss = 2.00, train acc = 16.4, early stopping loss = 1.96, early stopping acc = 58.4 (1.214 sec)\n",
            "2024-11-27 20:22:53: Epoch 20: Train loss = 1.94, train acc = 66.4, early stopping loss = 1.95, early stopping acc = 52.0 (0.470 sec)\n",
            "2024-11-27 20:22:53: Epoch 40: Train loss = 1.90, train acc = 70.0, early stopping loss = 1.95, early stopping acc = 52.8 (0.304 sec)\n",
            "2024-11-27 20:22:53: Epoch 60: Train loss = 1.85, train acc = 70.7, early stopping loss = 1.93, early stopping acc = 56.6 (0.310 sec)\n",
            "2024-11-27 20:22:54: Epoch 80: Train loss = 1.76, train acc = 76.4, early stopping loss = 1.90, early stopping acc = 59.6 (0.225 sec)\n",
            "2024-11-27 20:22:54: Epoch 100: Train loss = 1.68, train acc = 86.4, early stopping loss = 1.86, early stopping acc = 62.4 (0.213 sec)\n",
            "2024-11-27 20:22:54: Epoch 120: Train loss = 1.59, train acc = 91.4, early stopping loss = 1.80, early stopping acc = 68.4 (0.387 sec)\n",
            "2024-11-27 20:22:55: Epoch 140: Train loss = 1.52, train acc = 92.1, early stopping loss = 1.75, early stopping acc = 73.0 (0.399 sec)\n",
            "2024-11-27 20:22:55: Epoch 160: Train loss = 1.44, train acc = 95.0, early stopping loss = 1.69, early stopping acc = 77.0 (0.398 sec)\n",
            "2024-11-27 20:22:55: Epoch 180: Train loss = 1.38, train acc = 94.3, early stopping loss = 1.63, early stopping acc = 78.2 (0.313 sec)\n",
            "2024-11-27 20:22:56: Epoch 200: Train loss = 1.31, train acc = 95.0, early stopping loss = 1.59, early stopping acc = 78.0 (0.231 sec)\n",
            "2024-11-27 20:22:56: Epoch 220: Train loss = 1.25, train acc = 97.1, early stopping loss = 1.55, early stopping acc = 78.6 (0.275 sec)\n",
            "2024-11-27 20:22:56: Epoch 240: Train loss = 1.23, train acc = 96.4, early stopping loss = 1.51, early stopping acc = 79.4 (0.247 sec)\n",
            "2024-11-27 20:22:56: Epoch 260: Train loss = 1.16, train acc = 96.4, early stopping loss = 1.47, early stopping acc = 79.4 (0.200 sec)\n",
            "2024-11-27 20:22:57: Epoch 280: Train loss = 1.11, train acc = 97.1, early stopping loss = 1.44, early stopping acc = 80.0 (0.211 sec)\n",
            "2024-11-27 20:22:57: Epoch 300: Train loss = 1.10, train acc = 98.6, early stopping loss = 1.39, early stopping acc = 80.8 (0.274 sec)\n",
            "2024-11-27 20:22:57: Epoch 320: Train loss = 1.07, train acc = 97.9, early stopping loss = 1.38, early stopping acc = 80.6 (0.275 sec)\n",
            "2024-11-27 20:22:57: Epoch 340: Train loss = 1.01, train acc = 100.0, early stopping loss = 1.36, early stopping acc = 78.0 (0.196 sec)\n",
            "2024-11-27 20:22:58: Epoch 360: Train loss = 0.99, train acc = 98.6, early stopping loss = 1.33, early stopping acc = 80.4 (0.210 sec)\n",
            "2024-11-27 20:22:58: Epoch 380: Train loss = 0.97, train acc = 97.9, early stopping loss = 1.31, early stopping acc = 81.4 (0.215 sec)\n",
            "2024-11-27 20:22:58: Epoch 400: Train loss = 0.95, train acc = 97.9, early stopping loss = 1.28, early stopping acc = 80.6 (0.232 sec)\n",
            "2024-11-27 20:22:58: Epoch 420: Train loss = 0.92, train acc = 99.3, early stopping loss = 1.26, early stopping acc = 80.6 (0.259 sec)\n",
            "2024-11-27 20:22:58: Epoch 440: Train loss = 0.90, train acc = 99.3, early stopping loss = 1.24, early stopping acc = 81.0 (0.201 sec)\n",
            "2024-11-27 20:22:59: Epoch 460: Train loss = 0.88, train acc = 99.3, early stopping loss = 1.24, early stopping acc = 80.6 (0.229 sec)\n",
            "2024-11-27 20:22:59: Epoch 480: Train loss = 0.87, train acc = 100.0, early stopping loss = 1.24, early stopping acc = 81.8 (0.234 sec)\n",
            "2024-11-27 20:22:59: Epoch 500: Train loss = 0.85, train acc = 99.3, early stopping loss = 1.21, early stopping acc = 81.0 (0.209 sec)\n",
            "2024-11-27 20:22:59: Epoch 520: Train loss = 0.82, train acc = 99.3, early stopping loss = 1.18, early stopping acc = 81.0 (0.198 sec)\n",
            "2024-11-27 20:23:00: Epoch 540: Train loss = 0.83, train acc = 99.3, early stopping loss = 1.17, early stopping acc = 81.4 (0.243 sec)\n",
            "2024-11-27 20:23:00: Epoch 560: Train loss = 0.79, train acc = 98.6, early stopping loss = 1.17, early stopping acc = 80.8 (0.196 sec)\n",
            "2024-11-27 20:23:00: Epoch 580: Train loss = 0.77, train acc = 99.3, early stopping loss = 1.16, early stopping acc = 80.4 (0.285 sec)\n",
            "2024-11-27 20:23:00: Epoch 600: Train loss = 0.77, train acc = 99.3, early stopping loss = 1.15, early stopping acc = 80.4 (0.211 sec)\n",
            "2024-11-27 20:23:00: Epoch 620: Train loss = 0.74, train acc = 100.0, early stopping loss = 1.14, early stopping acc = 81.6 (0.198 sec)\n",
            "2024-11-27 20:23:01: Epoch 640: Train loss = 0.77, train acc = 100.0, early stopping loss = 1.12, early stopping acc = 81.0 (0.225 sec)\n",
            "2024-11-27 20:23:01: Epoch 660: Train loss = 0.74, train acc = 99.3, early stopping loss = 1.10, early stopping acc = 82.0 (0.206 sec)\n",
            "2024-11-27 20:23:01: Epoch 680: Train loss = 0.74, train acc = 99.3, early stopping loss = 1.10, early stopping acc = 81.4 (0.198 sec)\n",
            "2024-11-27 20:23:01: Epoch 700: Train loss = 0.72, train acc = 98.6, early stopping loss = 1.09, early stopping acc = 81.2 (0.216 sec)\n",
            "2024-11-27 20:23:01: Epoch 720: Train loss = 0.69, train acc = 100.0, early stopping loss = 1.08, early stopping acc = 81.0 (0.204 sec)\n",
            "2024-11-27 20:23:02: Epoch 740: Train loss = 0.69, train acc = 99.3, early stopping loss = 1.08, early stopping acc = 81.6 (0.231 sec)\n",
            "2024-11-27 20:23:02: Epoch 760: Train loss = 0.66, train acc = 99.3, early stopping loss = 1.08, early stopping acc = 80.8 (0.209 sec)\n",
            "2024-11-27 20:23:02: Epoch 780: Train loss = 0.66, train acc = 97.9, early stopping loss = 1.05, early stopping acc = 82.2 (0.201 sec)\n",
            "2024-11-27 20:23:02: Epoch 800: Train loss = 0.65, train acc = 99.3, early stopping loss = 1.05, early stopping acc = 81.0 (0.209 sec)\n",
            "2024-11-27 20:23:03: Epoch 820: Train loss = 0.64, train acc = 100.0, early stopping loss = 1.04, early stopping acc = 83.0 (0.201 sec)\n",
            "2024-11-27 20:23:03: Epoch 840: Train loss = 0.62, train acc = 100.0, early stopping loss = 1.05, early stopping acc = 80.4 (0.278 sec)\n",
            "2024-11-27 20:23:03: Epoch 860: Train loss = 0.64, train acc = 100.0, early stopping loss = 1.04, early stopping acc = 83.2 (0.207 sec)\n",
            "2024-11-27 20:23:03: Epoch 880: Train loss = 0.61, train acc = 100.0, early stopping loss = 1.04, early stopping acc = 81.2 (0.299 sec)\n",
            "2024-11-27 20:23:04: Epoch 900: Train loss = 0.63, train acc = 100.0, early stopping loss = 1.04, early stopping acc = 80.8 (0.277 sec)\n",
            "2024-11-27 20:23:04: Epoch 920: Train loss = 0.62, train acc = 100.0, early stopping loss = 1.03, early stopping acc = 82.6 (0.270 sec)\n",
            "2024-11-27 20:23:04: Epoch 940: Train loss = 0.59, train acc = 99.3, early stopping loss = 1.01, early stopping acc = 80.8 (0.278 sec)\n",
            "2024-11-27 20:23:04: Epoch 960: Train loss = 0.60, train acc = 99.3, early stopping loss = 0.99, early stopping acc = 82.0 (0.279 sec)\n",
            "2024-11-27 20:23:05: Epoch 980: Train loss = 0.60, train acc = 100.0, early stopping loss = 1.00, early stopping acc = 81.0 (0.321 sec)\n",
            "2024-11-27 20:23:05: Epoch 1000: Train loss = 0.59, train acc = 100.0, early stopping loss = 0.99, early stopping acc = 81.0 (0.305 sec)\n",
            "2024-11-27 20:23:05: Epoch 1020: Train loss = 0.57, train acc = 100.0, early stopping loss = 0.98, early stopping acc = 81.4 (0.302 sec)\n",
            "2024-11-27 20:23:06: Epoch 1040: Train loss = 0.55, train acc = 100.0, early stopping loss = 0.97, early stopping acc = 81.0 (0.237 sec)\n",
            "2024-11-27 20:23:06: Epoch 1060: Train loss = 0.56, train acc = 100.0, early stopping loss = 1.00, early stopping acc = 79.8 (0.234 sec)\n",
            "2024-11-27 20:23:06: Epoch 1080: Train loss = 0.56, train acc = 99.3, early stopping loss = 0.97, early stopping acc = 81.4 (0.214 sec)\n",
            "2024-11-27 20:23:06: Epoch 1100: Train loss = 0.57, train acc = 100.0, early stopping loss = 0.96, early stopping acc = 81.2 (0.283 sec)\n",
            "2024-11-27 20:23:07: Epoch 1120: Train loss = 0.53, train acc = 97.9, early stopping loss = 0.97, early stopping acc = 81.2 (0.200 sec)\n",
            "2024-11-27 20:23:07: Epoch 1140: Train loss = 0.55, train acc = 100.0, early stopping loss = 0.97, early stopping acc = 80.4 (0.200 sec)\n",
            "2024-11-27 20:23:07: Epoch 1160: Train loss = 0.51, train acc = 100.0, early stopping loss = 0.95, early stopping acc = 81.6 (0.195 sec)\n",
            "2024-11-27 20:23:07: Epoch 1180: Train loss = 0.56, train acc = 100.0, early stopping loss = 0.93, early stopping acc = 82.4 (0.206 sec)\n",
            "2024-11-27 20:23:07: Epoch 1200: Train loss = 0.53, train acc = 100.0, early stopping loss = 0.96, early stopping acc = 81.0 (0.199 sec)\n",
            "2024-11-27 20:23:08: Epoch 1220: Train loss = 0.54, train acc = 99.3, early stopping loss = 0.94, early stopping acc = 81.2 (0.198 sec)\n",
            "2024-11-27 20:23:08: Epoch 1240: Train loss = 0.52, train acc = 100.0, early stopping loss = 0.94, early stopping acc = 80.0 (0.198 sec)\n",
            "2024-11-27 20:23:08: Epoch 1260: Train loss = 0.53, train acc = 100.0, early stopping loss = 0.94, early stopping acc = 80.8 (0.196 sec)\n",
            "2024-11-27 20:23:08: Epoch 1280: Train loss = 0.51, train acc = 100.0, early stopping loss = 0.93, early stopping acc = 82.4 (0.206 sec)\n",
            "2024-11-27 20:23:08: Epoch 1300: Train loss = 0.51, train acc = 100.0, early stopping loss = 0.92, early stopping acc = 81.8 (0.199 sec)\n",
            "2024-11-27 20:23:09: Epoch 1320: Train loss = 0.51, train acc = 98.6, early stopping loss = 0.92, early stopping acc = 82.0 (0.196 sec)\n",
            "2024-11-27 20:23:09: Epoch 1340: Train loss = 0.50, train acc = 100.0, early stopping loss = 0.91, early stopping acc = 82.0 (0.285 sec)\n",
            "2024-11-27 20:23:09: Epoch 1360: Train loss = 0.49, train acc = 98.6, early stopping loss = 0.89, early stopping acc = 83.2 (0.197 sec)\n",
            "2024-11-27 20:23:09: Epoch 1380: Train loss = 0.49, train acc = 100.0, early stopping loss = 0.90, early stopping acc = 82.8 (0.213 sec)\n",
            "2024-11-27 20:23:09: Epoch 1400: Train loss = 0.49, train acc = 100.0, early stopping loss = 0.91, early stopping acc = 82.4 (0.200 sec)\n",
            "2024-11-27 20:23:10: Epoch 1420: Train loss = 0.45, train acc = 100.0, early stopping loss = 0.90, early stopping acc = 80.8 (0.202 sec)\n",
            "2024-11-27 20:23:10: Epoch 1440: Train loss = 0.47, train acc = 100.0, early stopping loss = 0.90, early stopping acc = 82.4 (0.197 sec)\n",
            "2024-11-27 20:23:10: Epoch 1460: Train loss = 0.51, train acc = 98.6, early stopping loss = 0.92, early stopping acc = 82.0 (0.199 sec)\n",
            "2024-11-27 20:23:10: Epoch 1480: Train loss = 0.48, train acc = 99.3, early stopping loss = 0.89, early stopping acc = 81.8 (0.209 sec)\n",
            "2024-11-27 20:23:10: Epoch 1500: Train loss = 0.46, train acc = 100.0, early stopping loss = 0.91, early stopping acc = 81.2 (0.198 sec)\n",
            "2024-11-27 20:23:11: Epoch 1520: Train loss = 0.46, train acc = 100.0, early stopping loss = 0.88, early stopping acc = 82.0 (0.199 sec)\n",
            "2024-11-27 20:23:11: Epoch 1540: Train loss = 0.44, train acc = 99.3, early stopping loss = 0.87, early stopping acc = 82.8 (0.197 sec)\n",
            "2024-11-27 20:23:11: Epoch 1560: Train loss = 0.46, train acc = 100.0, early stopping loss = 0.90, early stopping acc = 82.8 (0.199 sec)\n",
            "2024-11-27 20:23:11: Last epoch: 1572, best epoch: 1322 (19.977 sec)\n",
            "2024-11-27 20:23:11: Early stopping accuracy: 84.2%\n",
            "2024-11-27 20:23:11: Validation accuracy: 84.2%\n",
            "Training PPNP costs: 25.549017906188965 sec.\n",
            "/usr/local/lib/python3.10/dist-packages/scipy/sparse/_index.py:108: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            "Generating the new graph costs: 1.805121660232544 sec.\n",
            "2024-11-27 20:23:14: Fine-tuned model: {'hiddenunits': [64], 'drop_prob': 0.5, 'propagation': SDG()}\n",
            "2024-11-27 20:23:14: PyTorch seed: 1175707794\n",
            "2024-11-27 20:23:14: Epoch 0: Train loss = 0.48, train acc = 100.0, early stopping loss = 1.05, early stopping acc = 76.4 (0.017 sec)\n",
            "2024-11-27 20:23:14: Epoch 20: Train loss = 0.50, train acc = 99.3, early stopping loss = 0.92, early stopping acc = 81.4 (0.422 sec)\n",
            "2024-11-27 20:23:14: Epoch 40: Train loss = 0.47, train acc = 100.0, early stopping loss = 0.89, early stopping acc = 82.4 (0.248 sec)\n",
            "2024-11-27 20:23:15: Epoch 60: Train loss = 0.45, train acc = 100.0, early stopping loss = 0.88, early stopping acc = 83.0 (0.209 sec)\n",
            "2024-11-27 20:23:15: Epoch 80: Train loss = 0.45, train acc = 98.6, early stopping loss = 0.88, early stopping acc = 82.6 (0.204 sec)\n",
            "2024-11-27 20:23:15: Epoch 100: Train loss = 0.44, train acc = 99.3, early stopping loss = 0.89, early stopping acc = 81.0 (0.197 sec)\n",
            "2024-11-27 20:23:15: Epoch 120: Train loss = 0.46, train acc = 100.0, early stopping loss = 0.86, early stopping acc = 81.4 (0.213 sec)\n",
            "2024-11-27 20:23:15: Epoch 140: Train loss = 0.44, train acc = 99.3, early stopping loss = 0.89, early stopping acc = 82.4 (0.216 sec)\n",
            "2024-11-27 20:23:16: Epoch 160: Train loss = 0.45, train acc = 100.0, early stopping loss = 0.88, early stopping acc = 81.8 (0.288 sec)\n",
            "2024-11-27 20:23:16: Epoch 180: Train loss = 0.45, train acc = 99.3, early stopping loss = 0.89, early stopping acc = 82.8 (0.266 sec)\n",
            "2024-11-27 20:23:16: Epoch 200: Train loss = 0.45, train acc = 100.0, early stopping loss = 0.88, early stopping acc = 81.0 (0.278 sec)\n",
            "2024-11-27 20:23:17: Epoch 220: Train loss = 0.40, train acc = 100.0, early stopping loss = 0.84, early stopping acc = 83.0 (0.295 sec)\n",
            "2024-11-27 20:23:17: Epoch 240: Train loss = 0.41, train acc = 100.0, early stopping loss = 0.83, early stopping acc = 82.6 (0.280 sec)\n",
            "2024-11-27 20:23:17: Epoch 260: Train loss = 0.41, train acc = 100.0, early stopping loss = 0.86, early stopping acc = 81.4 (0.415 sec)\n",
            "2024-11-27 20:23:18: Epoch 280: Train loss = 0.42, train acc = 100.0, early stopping loss = 0.83, early stopping acc = 83.2 (0.308 sec)\n",
            "2024-11-27 20:23:18: Epoch 300: Train loss = 0.39, train acc = 100.0, early stopping loss = 0.83, early stopping acc = 82.6 (0.259 sec)\n",
            "2024-11-27 20:23:18: Epoch 320: Train loss = 0.39, train acc = 100.0, early stopping loss = 0.85, early stopping acc = 81.4 (0.208 sec)\n",
            "2024-11-27 20:23:18: Epoch 340: Train loss = 0.40, train acc = 99.3, early stopping loss = 0.84, early stopping acc = 82.2 (0.207 sec)\n",
            "2024-11-27 20:23:18: Epoch 360: Train loss = 0.41, train acc = 99.3, early stopping loss = 0.85, early stopping acc = 80.0 (0.208 sec)\n",
            "2024-11-27 20:23:19: Epoch 380: Train loss = 0.38, train acc = 100.0, early stopping loss = 0.85, early stopping acc = 80.6 (0.199 sec)\n",
            "2024-11-27 20:23:19: Epoch 400: Train loss = 0.38, train acc = 100.0, early stopping loss = 0.83, early stopping acc = 80.8 (0.204 sec)\n",
            "2024-11-27 20:23:19: Epoch 420: Train loss = 0.39, train acc = 100.0, early stopping loss = 0.82, early stopping acc = 82.2 (0.197 sec)\n",
            "2024-11-27 20:23:19: Epoch 440: Train loss = 0.39, train acc = 100.0, early stopping loss = 0.80, early stopping acc = 83.2 (0.202 sec)\n",
            "2024-11-27 20:23:19: Epoch 460: Train loss = 0.37, train acc = 99.3, early stopping loss = 0.81, early stopping acc = 82.4 (0.209 sec)\n",
            "2024-11-27 20:23:20: Epoch 480: Train loss = 0.37, train acc = 99.3, early stopping loss = 0.83, early stopping acc = 80.6 (0.208 sec)\n",
            "2024-11-27 20:23:20: Epoch 500: Train loss = 0.37, train acc = 100.0, early stopping loss = 0.79, early stopping acc = 82.2 (0.195 sec)\n",
            "2024-11-27 20:23:20: Epoch 520: Train loss = 0.36, train acc = 100.0, early stopping loss = 0.83, early stopping acc = 80.4 (0.281 sec)\n",
            "2024-11-27 20:23:20: Epoch 540: Train loss = 0.36, train acc = 100.0, early stopping loss = 0.81, early stopping acc = 83.2 (0.196 sec)\n",
            "2024-11-27 20:23:21: Epoch 560: Train loss = 0.34, train acc = 99.3, early stopping loss = 0.79, early stopping acc = 83.4 (0.203 sec)\n",
            "2024-11-27 20:23:21: Epoch 580: Train loss = 0.36, train acc = 100.0, early stopping loss = 0.80, early stopping acc = 81.0 (0.199 sec)\n",
            "2024-11-27 20:23:21: Last epoch: 583, best epoch: 467 (7.061 sec)\n",
            "2024-11-27 20:23:21: Early stopping accuracy: 84.4%\n",
            "2024-11-27 20:23:21: Validation accuracy: 84.3%\n",
            "Generating the new graph + Training SDG costs: 9.64382004737854 sec.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing the model on Citeseer Dataset"
      ],
      "metadata": {
        "id": "btTRKuhEYYys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit\n",
        "!python SDG-main/code/main.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9umqLR2lUK7Y",
        "outputId": "400201e8-c01c-486c-eb28-934bd4196819"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/SDG-main/code/sdg/data/sparsegraph.py:397: UserWarning: 124 self loops removed\n",
            "  warnings.warn(\"{0} self loops removed\".format(num_self_loops))\n",
            "2024-11-27 20:34:20: agnostic_model: {'hiddenunits': [64], 'drop_prob': 0.5, 'propagation': PPRExact()}\n",
            "2024-11-27 20:34:20: PyTorch seed: 4050665564\n",
            "/content/SDG-main/code/sdg/pytorch_code/utils.py:74: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:651.)\n",
            "  return torch.sparse.FloatTensor(\n",
            "2024-11-27 20:34:21: Epoch 0: Train loss = 1.85, train acc = 21.7, early stopping loss = 1.81, early stopping acc = 65.0 (0.374 sec)\n",
            "2024-11-27 20:34:22: Epoch 20: Train loss = 1.78, train acc = 67.5, early stopping loss = 1.78, early stopping acc = 65.6 (0.283 sec)\n",
            "2024-11-27 20:34:22: Epoch 40: Train loss = 1.72, train acc = 69.2, early stopping loss = 1.73, early stopping acc = 69.0 (0.241 sec)\n",
            "2024-11-27 20:34:22: Epoch 60: Train loss = 1.62, train acc = 72.5, early stopping loss = 1.66, early stopping acc = 71.4 (0.327 sec)\n",
            "2024-11-27 20:34:22: Epoch 80: Train loss = 1.55, train acc = 80.8, early stopping loss = 1.59, early stopping acc = 72.2 (0.253 sec)\n",
            "2024-11-27 20:34:23: Epoch 100: Train loss = 1.46, train acc = 81.7, early stopping loss = 1.54, early stopping acc = 73.4 (0.267 sec)\n",
            "2024-11-27 20:34:23: Epoch 120: Train loss = 1.36, train acc = 85.8, early stopping loss = 1.50, early stopping acc = 74.0 (0.256 sec)\n",
            "2024-11-27 20:34:23: Epoch 140: Train loss = 1.28, train acc = 88.3, early stopping loss = 1.46, early stopping acc = 74.4 (0.211 sec)\n",
            "2024-11-27 20:34:23: Epoch 160: Train loss = 1.23, train acc = 89.2, early stopping loss = 1.43, early stopping acc = 73.2 (0.288 sec)\n",
            "2024-11-27 20:34:24: Epoch 180: Train loss = 1.17, train acc = 86.7, early stopping loss = 1.40, early stopping acc = 73.2 (0.206 sec)\n",
            "2024-11-27 20:34:24: Epoch 200: Train loss = 1.12, train acc = 87.5, early stopping loss = 1.38, early stopping acc = 71.8 (0.203 sec)\n",
            "2024-11-27 20:34:24: Epoch 220: Train loss = 1.07, train acc = 95.8, early stopping loss = 1.36, early stopping acc = 74.6 (0.203 sec)\n",
            "2024-11-27 20:34:24: Epoch 240: Train loss = 1.05, train acc = 91.7, early stopping loss = 1.35, early stopping acc = 73.0 (0.198 sec)\n",
            "2024-11-27 20:34:25: Epoch 260: Train loss = 0.99, train acc = 95.0, early stopping loss = 1.33, early stopping acc = 73.2 (0.209 sec)\n",
            "2024-11-27 20:34:25: Epoch 280: Train loss = 0.97, train acc = 94.2, early stopping loss = 1.32, early stopping acc = 73.2 (0.195 sec)\n",
            "2024-11-27 20:34:25: Epoch 300: Train loss = 0.96, train acc = 92.5, early stopping loss = 1.32, early stopping acc = 73.4 (0.195 sec)\n",
            "2024-11-27 20:34:25: Epoch 320: Train loss = 0.92, train acc = 92.5, early stopping loss = 1.30, early stopping acc = 72.4 (0.203 sec)\n",
            "2024-11-27 20:34:25: Epoch 340: Train loss = 0.89, train acc = 95.0, early stopping loss = 1.28, early stopping acc = 72.4 (0.198 sec)\n",
            "2024-11-27 20:34:26: Epoch 360: Train loss = 0.89, train acc = 95.0, early stopping loss = 1.30, early stopping acc = 72.6 (0.208 sec)\n",
            "2024-11-27 20:34:26: Epoch 380: Train loss = 0.85, train acc = 95.0, early stopping loss = 1.27, early stopping acc = 72.6 (0.195 sec)\n",
            "2024-11-27 20:34:26: Epoch 400: Train loss = 0.83, train acc = 95.8, early stopping loss = 1.26, early stopping acc = 72.6 (0.197 sec)\n",
            "2024-11-27 20:34:26: Epoch 420: Train loss = 0.79, train acc = 97.5, early stopping loss = 1.25, early stopping acc = 72.0 (0.199 sec)\n",
            "2024-11-27 20:34:26: Epoch 440: Train loss = 0.79, train acc = 97.5, early stopping loss = 1.26, early stopping acc = 71.0 (0.198 sec)\n",
            "2024-11-27 20:34:27: Epoch 460: Train loss = 0.77, train acc = 96.7, early stopping loss = 1.25, early stopping acc = 71.8 (0.207 sec)\n",
            "2024-11-27 20:34:27: Epoch 480: Train loss = 0.76, train acc = 95.0, early stopping loss = 1.25, early stopping acc = 71.2 (0.206 sec)\n",
            "2024-11-27 20:34:27: Epoch 500: Train loss = 0.76, train acc = 96.7, early stopping loss = 1.26, early stopping acc = 70.6 (0.197 sec)\n",
            "2024-11-27 20:34:27: Epoch 520: Train loss = 0.74, train acc = 96.7, early stopping loss = 1.24, early stopping acc = 70.8 (0.202 sec)\n",
            "2024-11-27 20:34:27: Epoch 540: Train loss = 0.74, train acc = 95.8, early stopping loss = 1.21, early stopping acc = 71.8 (0.198 sec)\n",
            "2024-11-27 20:34:28: Epoch 560: Train loss = 0.70, train acc = 98.3, early stopping loss = 1.24, early stopping acc = 70.4 (0.196 sec)\n",
            "2024-11-27 20:34:28: Epoch 580: Train loss = 0.71, train acc = 95.0, early stopping loss = 1.21, early stopping acc = 72.6 (0.203 sec)\n",
            "2024-11-27 20:34:28: Epoch 600: Train loss = 0.69, train acc = 99.2, early stopping loss = 1.20, early stopping acc = 72.0 (0.197 sec)\n",
            "2024-11-27 20:34:28: Epoch 620: Train loss = 0.65, train acc = 99.2, early stopping loss = 1.20, early stopping acc = 71.6 (0.203 sec)\n",
            "2024-11-27 20:34:28: Epoch 640: Train loss = 0.65, train acc = 95.8, early stopping loss = 1.20, early stopping acc = 71.0 (0.202 sec)\n",
            "2024-11-27 20:34:29: Epoch 660: Train loss = 0.62, train acc = 98.3, early stopping loss = 1.19, early stopping acc = 71.4 (0.285 sec)\n",
            "2024-11-27 20:34:29: Epoch 680: Train loss = 0.66, train acc = 99.2, early stopping loss = 1.20, early stopping acc = 71.0 (0.195 sec)\n",
            "2024-11-27 20:34:29: Epoch 700: Train loss = 0.62, train acc = 97.5, early stopping loss = 1.19, early stopping acc = 71.2 (0.203 sec)\n",
            "2024-11-27 20:34:29: Epoch 720: Train loss = 0.65, train acc = 95.8, early stopping loss = 1.19, early stopping acc = 71.4 (0.201 sec)\n",
            "2024-11-27 20:34:29: Epoch 740: Train loss = 0.62, train acc = 99.2, early stopping loss = 1.18, early stopping acc = 71.6 (0.230 sec)\n",
            "2024-11-27 20:34:30: Epoch 760: Train loss = 0.62, train acc = 98.3, early stopping loss = 1.21, early stopping acc = 70.2 (0.227 sec)\n",
            "2024-11-27 20:34:30: Epoch 780: Train loss = 0.59, train acc = 95.0, early stopping loss = 1.17, early stopping acc = 71.6 (0.198 sec)\n",
            "2024-11-27 20:34:30: Epoch 800: Train loss = 0.61, train acc = 95.8, early stopping loss = 1.19, early stopping acc = 71.0 (0.197 sec)\n",
            "2024-11-27 20:34:30: Epoch 820: Train loss = 0.55, train acc = 100.0, early stopping loss = 1.17, early stopping acc = 71.2 (0.233 sec)\n",
            "2024-11-27 20:34:31: Epoch 840: Train loss = 0.59, train acc = 98.3, early stopping loss = 1.21, early stopping acc = 70.4 (0.272 sec)\n",
            "2024-11-27 20:34:31: Epoch 860: Train loss = 0.55, train acc = 98.3, early stopping loss = 1.17, early stopping acc = 70.4 (0.274 sec)\n",
            "2024-11-27 20:34:31: Epoch 880: Train loss = 0.56, train acc = 96.7, early stopping loss = 1.16, early stopping acc = 71.4 (0.268 sec)\n",
            "2024-11-27 20:34:31: Epoch 900: Train loss = 0.57, train acc = 99.2, early stopping loss = 1.15, early stopping acc = 71.2 (0.266 sec)\n",
            "2024-11-27 20:34:32: Epoch 920: Train loss = 0.57, train acc = 97.5, early stopping loss = 1.18, early stopping acc = 70.4 (0.277 sec)\n",
            "2024-11-27 20:34:32: Epoch 940: Train loss = 0.54, train acc = 100.0, early stopping loss = 1.18, early stopping acc = 70.6 (0.290 sec)\n",
            "2024-11-27 20:34:32: Epoch 960: Train loss = 0.55, train acc = 97.5, early stopping loss = 1.15, early stopping acc = 70.6 (0.299 sec)\n",
            "2024-11-27 20:34:32: Epoch 980: Train loss = 0.55, train acc = 99.2, early stopping loss = 1.17, early stopping acc = 69.8 (0.272 sec)\n",
            "2024-11-27 20:34:33: Epoch 1000: Train loss = 0.54, train acc = 97.5, early stopping loss = 1.15, early stopping acc = 71.4 (0.207 sec)\n",
            "2024-11-27 20:34:33: Epoch 1020: Train loss = 0.52, train acc = 100.0, early stopping loss = 1.18, early stopping acc = 69.8 (0.215 sec)\n",
            "2024-11-27 20:34:33: Epoch 1040: Train loss = 0.53, train acc = 97.5, early stopping loss = 1.18, early stopping acc = 70.2 (0.204 sec)\n",
            "2024-11-27 20:34:33: Epoch 1060: Train loss = 0.53, train acc = 99.2, early stopping loss = 1.17, early stopping acc = 69.6 (0.202 sec)\n",
            "2024-11-27 20:34:34: Epoch 1080: Train loss = 0.50, train acc = 99.2, early stopping loss = 1.19, early stopping acc = 69.4 (0.197 sec)\n",
            "2024-11-27 20:34:34: Epoch 1100: Train loss = 0.54, train acc = 95.8, early stopping loss = 1.16, early stopping acc = 70.6 (0.194 sec)\n",
            "2024-11-27 20:34:34: Epoch 1120: Train loss = 0.48, train acc = 99.2, early stopping loss = 1.15, early stopping acc = 71.4 (0.205 sec)\n",
            "2024-11-27 20:34:34: Epoch 1140: Train loss = 0.52, train acc = 99.2, early stopping loss = 1.14, early stopping acc = 71.2 (0.198 sec)\n",
            "2024-11-27 20:34:34: Epoch 1160: Train loss = 0.50, train acc = 100.0, early stopping loss = 1.15, early stopping acc = 71.8 (0.273 sec)\n",
            "2024-11-27 20:34:35: Epoch 1180: Train loss = 0.50, train acc = 100.0, early stopping loss = 1.18, early stopping acc = 69.6 (0.198 sec)\n",
            "2024-11-27 20:34:35: Epoch 1200: Train loss = 0.51, train acc = 97.5, early stopping loss = 1.17, early stopping acc = 69.6 (0.200 sec)\n",
            "2024-11-27 20:34:35: Epoch 1220: Train loss = 0.49, train acc = 98.3, early stopping loss = 1.13, early stopping acc = 70.2 (0.211 sec)\n",
            "2024-11-27 20:34:35: Epoch 1240: Train loss = 0.48, train acc = 97.5, early stopping loss = 1.13, early stopping acc = 70.0 (0.200 sec)\n",
            "2024-11-27 20:34:35: Last epoch: 1249, best epoch: 136 (14.300 sec)\n",
            "2024-11-27 20:34:35: Early stopping accuracy: 75.0%\n",
            "2024-11-27 20:34:35: Validation accuracy: 73.3%\n",
            "Training PPNP costs: 16.754567623138428 sec.\n",
            "/usr/local/lib/python3.10/dist-packages/scipy/sparse/_index.py:108: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            "Generating the new graph costs: 0.8379871845245361 sec.\n",
            "2024-11-27 20:34:36: Fine-tuned model: {'hiddenunits': [64], 'drop_prob': 0.5, 'propagation': SDG()}\n",
            "2024-11-27 20:34:36: PyTorch seed: 3620127439\n",
            "2024-11-27 20:34:36: Epoch 0: Train loss = 1.31, train acc = 84.2, early stopping loss = 1.47, early stopping acc = 74.4 (0.012 sec)\n",
            "2024-11-27 20:34:37: Epoch 20: Train loss = 1.21, train acc = 87.5, early stopping loss = 1.42, early stopping acc = 72.6 (0.252 sec)\n",
            "2024-11-27 20:34:37: Epoch 40: Train loss = 1.16, train acc = 92.5, early stopping loss = 1.39, early stopping acc = 73.4 (0.227 sec)\n",
            "2024-11-27 20:34:37: Epoch 60: Train loss = 1.12, train acc = 89.2, early stopping loss = 1.37, early stopping acc = 72.4 (0.222 sec)\n",
            "2024-11-27 20:34:37: Epoch 80: Train loss = 1.11, train acc = 90.8, early stopping loss = 1.34, early stopping acc = 72.4 (0.203 sec)\n",
            "2024-11-27 20:34:38: Epoch 100: Train loss = 1.05, train acc = 90.0, early stopping loss = 1.32, early stopping acc = 73.6 (0.201 sec)\n",
            "2024-11-27 20:34:38: Epoch 120: Train loss = 1.01, train acc = 94.2, early stopping loss = 1.32, early stopping acc = 73.0 (0.195 sec)\n",
            "2024-11-27 20:34:38: Epoch 140: Train loss = 0.97, train acc = 90.8, early stopping loss = 1.30, early stopping acc = 73.0 (0.213 sec)\n",
            "2024-11-27 20:34:38: Epoch 160: Train loss = 0.94, train acc = 95.8, early stopping loss = 1.29, early stopping acc = 72.6 (0.198 sec)\n",
            "2024-11-27 20:34:38: Epoch 180: Train loss = 0.88, train acc = 95.0, early stopping loss = 1.28, early stopping acc = 72.4 (0.199 sec)\n",
            "2024-11-27 20:34:39: Epoch 200: Train loss = 0.90, train acc = 95.0, early stopping loss = 1.26, early stopping acc = 72.4 (0.279 sec)\n",
            "2024-11-27 20:34:39: Epoch 220: Train loss = 0.87, train acc = 93.3, early stopping loss = 1.27, early stopping acc = 72.8 (0.197 sec)\n",
            "2024-11-27 20:34:39: Epoch 240: Train loss = 0.85, train acc = 91.7, early stopping loss = 1.25, early stopping acc = 72.4 (0.209 sec)\n",
            "2024-11-27 20:34:39: Epoch 260: Train loss = 0.84, train acc = 94.2, early stopping loss = 1.25, early stopping acc = 71.6 (0.197 sec)\n",
            "2024-11-27 20:34:39: Epoch 280: Train loss = 0.78, train acc = 95.8, early stopping loss = 1.24, early stopping acc = 72.6 (0.213 sec)\n",
            "2024-11-27 20:34:40: Epoch 300: Train loss = 0.79, train acc = 97.5, early stopping loss = 1.23, early stopping acc = 71.8 (0.197 sec)\n",
            "2024-11-27 20:34:40: Epoch 320: Train loss = 0.78, train acc = 96.7, early stopping loss = 1.23, early stopping acc = 72.0 (0.203 sec)\n",
            "2024-11-27 20:34:40: Epoch 340: Train loss = 0.74, train acc = 95.8, early stopping loss = 1.22, early stopping acc = 71.6 (0.217 sec)\n",
            "2024-11-27 20:34:40: Epoch 360: Train loss = 0.71, train acc = 98.3, early stopping loss = 1.21, early stopping acc = 71.0 (0.198 sec)\n",
            "2024-11-27 20:34:40: Epoch 380: Train loss = 0.74, train acc = 95.8, early stopping loss = 1.22, early stopping acc = 71.6 (0.196 sec)\n",
            "2024-11-27 20:34:41: Epoch 400: Train loss = 0.71, train acc = 95.8, early stopping loss = 1.20, early stopping acc = 71.6 (0.196 sec)\n",
            "2024-11-27 20:34:41: Epoch 420: Train loss = 0.71, train acc = 98.3, early stopping loss = 1.19, early stopping acc = 72.2 (0.200 sec)\n",
            "2024-11-27 20:34:41: Epoch 440: Train loss = 0.70, train acc = 95.0, early stopping loss = 1.20, early stopping acc = 71.2 (0.208 sec)\n",
            "2024-11-27 20:34:41: Epoch 460: Train loss = 0.65, train acc = 97.5, early stopping loss = 1.19, early stopping acc = 71.4 (0.281 sec)\n",
            "2024-11-27 20:34:42: Epoch 480: Train loss = 0.66, train acc = 98.3, early stopping loss = 1.19, early stopping acc = 72.0 (0.196 sec)\n",
            "2024-11-27 20:34:42: Epoch 500: Train loss = 0.66, train acc = 96.7, early stopping loss = 1.18, early stopping acc = 71.8 (0.196 sec)\n",
            "2024-11-27 20:34:42: Epoch 520: Train loss = 0.62, train acc = 98.3, early stopping loss = 1.20, early stopping acc = 70.8 (0.197 sec)\n",
            "2024-11-27 20:34:42: Epoch 540: Train loss = 0.63, train acc = 98.3, early stopping loss = 1.17, early stopping acc = 71.2 (0.206 sec)\n",
            "2024-11-27 20:34:42: Epoch 560: Train loss = 0.60, train acc = 98.3, early stopping loss = 1.16, early stopping acc = 72.8 (0.198 sec)\n",
            "2024-11-27 20:34:43: Epoch 580: Train loss = 0.60, train acc = 97.5, early stopping loss = 1.19, early stopping acc = 70.6 (0.243 sec)\n",
            "2024-11-27 20:34:43: Epoch 600: Train loss = 0.59, train acc = 99.2, early stopping loss = 1.17, early stopping acc = 70.6 (0.270 sec)\n",
            "2024-11-27 20:34:43: Epoch 620: Train loss = 0.58, train acc = 98.3, early stopping loss = 1.18, early stopping acc = 69.6 (0.282 sec)\n",
            "2024-11-27 20:34:43: Epoch 640: Train loss = 0.58, train acc = 99.2, early stopping loss = 1.19, early stopping acc = 69.4 (0.266 sec)\n",
            "2024-11-27 20:34:44: Epoch 660: Train loss = 0.59, train acc = 97.5, early stopping loss = 1.19, early stopping acc = 69.6 (0.268 sec)\n",
            "2024-11-27 20:34:44: Epoch 680: Train loss = 0.59, train acc = 98.3, early stopping loss = 1.17, early stopping acc = 70.2 (0.283 sec)\n",
            "2024-11-27 20:34:44: Epoch 700: Train loss = 0.57, train acc = 99.2, early stopping loss = 1.18, early stopping acc = 69.6 (0.411 sec)\n",
            "2024-11-27 20:34:45: Epoch 720: Train loss = 0.55, train acc = 100.0, early stopping loss = 1.15, early stopping acc = 71.0 (0.289 sec)\n",
            "2024-11-27 20:34:45: Epoch 740: Train loss = 0.55, train acc = 99.2, early stopping loss = 1.14, early stopping acc = 72.0 (0.217 sec)\n",
            "2024-11-27 20:34:45: Epoch 760: Train loss = 0.56, train acc = 95.0, early stopping loss = 1.19, early stopping acc = 69.8 (0.211 sec)\n",
            "2024-11-27 20:34:45: Epoch 780: Train loss = 0.54, train acc = 99.2, early stopping loss = 1.17, early stopping acc = 70.4 (0.206 sec)\n",
            "2024-11-27 20:34:46: Epoch 800: Train loss = 0.53, train acc = 99.2, early stopping loss = 1.17, early stopping acc = 69.6 (0.202 sec)\n",
            "2024-11-27 20:34:46: Epoch 820: Train loss = 0.54, train acc = 98.3, early stopping loss = 1.16, early stopping acc = 71.0 (0.195 sec)\n",
            "2024-11-27 20:34:46: Epoch 840: Train loss = 0.53, train acc = 99.2, early stopping loss = 1.15, early stopping acc = 71.6 (0.200 sec)\n",
            "2024-11-27 20:34:46: Epoch 860: Train loss = 0.52, train acc = 95.8, early stopping loss = 1.17, early stopping acc = 70.0 (0.195 sec)\n",
            "2024-11-27 20:34:46: Epoch 880: Train loss = 0.49, train acc = 99.2, early stopping loss = 1.15, early stopping acc = 71.8 (0.207 sec)\n",
            "2024-11-27 20:34:47: Epoch 900: Train loss = 0.52, train acc = 98.3, early stopping loss = 1.15, early stopping acc = 69.4 (0.196 sec)\n",
            "2024-11-27 20:34:47: Epoch 920: Train loss = 0.49, train acc = 99.2, early stopping loss = 1.15, early stopping acc = 70.0 (0.193 sec)\n",
            "2024-11-27 20:34:47: Epoch 940: Train loss = 0.50, train acc = 100.0, early stopping loss = 1.12, early stopping acc = 71.4 (0.205 sec)\n",
            "2024-11-27 20:34:47: Epoch 960: Train loss = 0.49, train acc = 99.2, early stopping loss = 1.17, early stopping acc = 68.8 (0.282 sec)\n",
            "2024-11-27 20:34:47: Epoch 980: Train loss = 0.49, train acc = 99.2, early stopping loss = 1.15, early stopping acc = 71.0 (0.198 sec)\n",
            "2024-11-27 20:34:48: Epoch 1000: Train loss = 0.50, train acc = 97.5, early stopping loss = 1.16, early stopping acc = 70.0 (0.199 sec)\n",
            "2024-11-27 20:34:48: Last epoch: 1003, best epoch: 1 (11.156 sec)\n",
            "2024-11-27 20:34:48: Early stopping accuracy: 74.4%\n",
            "2024-11-27 20:34:48: Validation accuracy: 73.5%\n",
            "Generating the new graph + Training SDG costs: 12.338519811630249 sec.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing the model on Pubmed Dataset"
      ],
      "metadata": {
        "id": "27Kn2RjgYjjs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit\n",
        "!python SDG-main/code/main.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQ0NE-hfVPT3",
        "outputId": "b8f00a05-32e7-47a5-b70a-c625974dc373"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-27 20:53:49: agnostic_model: {'hiddenunits': [64], 'drop_prob': 0.5, 'propagation': PPRExact()}\n",
            "2024-11-27 20:53:49: PyTorch seed: 775529652\n",
            "/content/SDG-main/code/sdg/pytorch_code/utils.py:74: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:651.)\n",
            "  return torch.sparse.FloatTensor(\n",
            "2024-11-27 20:53:51: Epoch 0: Train loss = 1.15, train acc = 33.3, early stopping loss = 1.12, early stopping acc = 50.0 (0.449 sec)\n",
            "2024-11-27 20:54:00: Epoch 20: Train loss = 1.07, train acc = 85.0, early stopping loss = 1.08, early stopping acc = 77.6 (9.262 sec)\n",
            "2024-11-27 20:54:01: Epoch 40: Train loss = 0.97, train acc = 86.7, early stopping loss = 1.02, early stopping acc = 79.2 (0.708 sec)\n",
            "2024-11-27 20:54:06: Epoch 60: Train loss = 0.89, train acc = 90.0, early stopping loss = 0.96, early stopping acc = 80.8 (5.353 sec)\n",
            "2024-11-27 20:54:14: Epoch 80: Train loss = 0.78, train acc = 95.0, early stopping loss = 0.91, early stopping acc = 80.4 (8.264 sec)\n",
            "2024-11-27 20:54:15: Epoch 100: Train loss = 0.72, train acc = 98.3, early stopping loss = 0.87, early stopping acc = 81.0 (0.823 sec)\n",
            "2024-11-27 20:54:16: Epoch 120: Train loss = 0.68, train acc = 95.0, early stopping loss = 0.84, early stopping acc = 81.2 (0.714 sec)\n",
            "2024-11-27 20:54:19: Epoch 140: Train loss = 0.64, train acc = 95.0, early stopping loss = 0.82, early stopping acc = 81.8 (3.073 sec)\n",
            "2024-11-27 20:54:20: Epoch 160: Train loss = 0.58, train acc = 96.7, early stopping loss = 0.79, early stopping acc = 82.2 (0.716 sec)\n",
            "2024-11-27 20:54:23: Epoch 180: Train loss = 0.55, train acc = 98.3, early stopping loss = 0.77, early stopping acc = 82.0 (3.185 sec)\n",
            "2024-11-27 20:54:24: Epoch 200: Train loss = 0.56, train acc = 96.7, early stopping loss = 0.76, early stopping acc = 81.8 (0.780 sec)\n",
            "2024-11-27 20:54:24: Epoch 220: Train loss = 0.53, train acc = 98.3, early stopping loss = 0.73, early stopping acc = 81.4 (0.765 sec)\n",
            "2024-11-27 20:54:25: Epoch 240: Train loss = 0.48, train acc = 98.3, early stopping loss = 0.74, early stopping acc = 82.2 (0.717 sec)\n",
            "2024-11-27 20:54:26: Epoch 260: Train loss = 0.47, train acc = 100.0, early stopping loss = 0.72, early stopping acc = 81.0 (0.715 sec)\n",
            "2024-11-27 20:54:26: Epoch 280: Train loss = 0.47, train acc = 100.0, early stopping loss = 0.70, early stopping acc = 82.0 (0.712 sec)\n",
            "2024-11-27 20:54:27: Epoch 300: Train loss = 0.44, train acc = 98.3, early stopping loss = 0.72, early stopping acc = 80.6 (0.713 sec)\n",
            "2024-11-27 20:54:28: Epoch 320: Train loss = 0.42, train acc = 100.0, early stopping loss = 0.71, early stopping acc = 81.0 (0.715 sec)\n",
            "2024-11-27 20:54:29: Epoch 340: Train loss = 0.40, train acc = 98.3, early stopping loss = 0.69, early stopping acc = 82.2 (0.715 sec)\n",
            "2024-11-27 20:54:29: Epoch 360: Train loss = 0.39, train acc = 100.0, early stopping loss = 0.67, early stopping acc = 82.0 (0.712 sec)\n",
            "2024-11-27 20:54:30: Epoch 380: Train loss = 0.41, train acc = 100.0, early stopping loss = 0.68, early stopping acc = 79.2 (0.714 sec)\n",
            "2024-11-27 20:54:31: Epoch 400: Train loss = 0.37, train acc = 100.0, early stopping loss = 0.66, early stopping acc = 81.2 (0.714 sec)\n",
            "2024-11-27 20:54:31: Epoch 420: Train loss = 0.39, train acc = 98.3, early stopping loss = 0.67, early stopping acc = 82.0 (0.714 sec)\n",
            "2024-11-27 20:54:33: Epoch 440: Train loss = 0.36, train acc = 100.0, early stopping loss = 0.66, early stopping acc = 80.0 (1.858 sec)\n",
            "2024-11-27 20:54:37: Epoch 460: Train loss = 0.39, train acc = 98.3, early stopping loss = 0.65, early stopping acc = 82.8 (3.504 sec)\n",
            "2024-11-27 20:54:38: Epoch 480: Train loss = 0.33, train acc = 98.3, early stopping loss = 0.63, early stopping acc = 82.8 (0.785 sec)\n",
            "2024-11-27 20:54:41: Epoch 500: Train loss = 0.33, train acc = 98.3, early stopping loss = 0.64, early stopping acc = 81.6 (3.041 sec)\n",
            "2024-11-27 20:54:41: Epoch 520: Train loss = 0.34, train acc = 100.0, early stopping loss = 0.65, early stopping acc = 79.0 (0.717 sec)\n",
            "2024-11-27 20:54:42: Epoch 540: Train loss = 0.34, train acc = 100.0, early stopping loss = 0.65, early stopping acc = 78.8 (0.716 sec)\n",
            "2024-11-27 20:54:43: Epoch 560: Train loss = 0.32, train acc = 100.0, early stopping loss = 0.64, early stopping acc = 81.6 (0.717 sec)\n",
            "2024-11-27 20:54:43: Epoch 580: Train loss = 0.33, train acc = 100.0, early stopping loss = 0.62, early stopping acc = 81.2 (0.722 sec)\n",
            "2024-11-27 20:54:44: Epoch 600: Train loss = 0.33, train acc = 100.0, early stopping loss = 0.60, early stopping acc = 82.2 (0.792 sec)\n",
            "2024-11-27 20:54:45: Epoch 620: Train loss = 0.32, train acc = 96.7, early stopping loss = 0.63, early stopping acc = 80.8 (0.712 sec)\n",
            "2024-11-27 20:54:46: Epoch 640: Train loss = 0.32, train acc = 100.0, early stopping loss = 0.65, early stopping acc = 78.2 (0.716 sec)\n",
            "2024-11-27 20:54:46: Epoch 660: Train loss = 0.32, train acc = 98.3, early stopping loss = 0.65, early stopping acc = 79.0 (0.735 sec)\n",
            "2024-11-27 20:54:47: Epoch 680: Train loss = 0.31, train acc = 100.0, early stopping loss = 0.60, early stopping acc = 81.0 (0.780 sec)\n",
            "2024-11-27 20:54:48: Epoch 700: Train loss = 0.28, train acc = 100.0, early stopping loss = 0.62, early stopping acc = 79.0 (0.773 sec)\n",
            "2024-11-27 20:54:49: Epoch 720: Train loss = 0.28, train acc = 100.0, early stopping loss = 0.62, early stopping acc = 79.4 (0.765 sec)\n",
            "2024-11-27 20:54:49: Epoch 740: Train loss = 0.29, train acc = 100.0, early stopping loss = 0.60, early stopping acc = 82.4 (0.716 sec)\n",
            "2024-11-27 20:54:50: Epoch 760: Train loss = 0.26, train acc = 100.0, early stopping loss = 0.61, early stopping acc = 82.2 (0.719 sec)\n",
            "2024-11-27 20:54:51: Epoch 780: Train loss = 0.26, train acc = 100.0, early stopping loss = 0.62, early stopping acc = 79.2 (0.714 sec)\n",
            "2024-11-27 20:54:52: Epoch 800: Train loss = 0.25, train acc = 100.0, early stopping loss = 0.63, early stopping acc = 79.6 (0.722 sec)\n",
            "2024-11-27 20:54:52: Epoch 820: Train loss = 0.27, train acc = 100.0, early stopping loss = 0.61, early stopping acc = 79.8 (0.722 sec)\n",
            "2024-11-27 20:54:53: Epoch 840: Train loss = 0.27, train acc = 100.0, early stopping loss = 0.60, early stopping acc = 79.4 (0.716 sec)\n",
            "2024-11-27 20:54:54: Epoch 860: Train loss = 0.28, train acc = 100.0, early stopping loss = 0.59, early stopping acc = 82.0 (0.797 sec)\n",
            "2024-11-27 20:54:55: Epoch 880: Train loss = 0.28, train acc = 98.3, early stopping loss = 0.58, early stopping acc = 81.6 (0.724 sec)\n",
            "2024-11-27 20:54:55: Epoch 900: Train loss = 0.24, train acc = 100.0, early stopping loss = 0.62, early stopping acc = 80.4 (0.726 sec)\n",
            "2024-11-27 20:54:56: Epoch 920: Train loss = 0.24, train acc = 100.0, early stopping loss = 0.60, early stopping acc = 79.6 (0.719 sec)\n",
            "2024-11-27 20:54:57: Epoch 940: Train loss = 0.24, train acc = 100.0, early stopping loss = 0.60, early stopping acc = 79.6 (0.719 sec)\n",
            "2024-11-27 20:54:57: Epoch 960: Train loss = 0.26, train acc = 100.0, early stopping loss = 0.61, early stopping acc = 80.8 (0.719 sec)\n",
            "2024-11-27 20:54:58: Epoch 980: Train loss = 0.25, train acc = 100.0, early stopping loss = 0.58, early stopping acc = 81.4 (0.719 sec)\n",
            "2024-11-27 20:54:59: Epoch 1000: Train loss = 0.27, train acc = 100.0, early stopping loss = 0.59, early stopping acc = 80.0 (0.758 sec)\n",
            "2024-11-27 20:55:00: Epoch 1020: Train loss = 0.24, train acc = 100.0, early stopping loss = 0.62, early stopping acc = 78.4 (0.782 sec)\n",
            "2024-11-27 20:55:01: Epoch 1040: Train loss = 0.24, train acc = 98.3, early stopping loss = 0.59, early stopping acc = 79.4 (0.790 sec)\n",
            "2024-11-27 20:55:01: Epoch 1060: Train loss = 0.23, train acc = 100.0, early stopping loss = 0.56, early stopping acc = 83.8 (0.728 sec)\n",
            "2024-11-27 20:55:03: Epoch 1080: Train loss = 0.23, train acc = 98.3, early stopping loss = 0.58, early stopping acc = 81.0 (1.874 sec)\n",
            "2024-11-27 20:55:04: Epoch 1100: Train loss = 0.24, train acc = 100.0, early stopping loss = 0.60, early stopping acc = 79.4 (0.724 sec)\n",
            "2024-11-27 20:55:05: Epoch 1120: Train loss = 0.22, train acc = 100.0, early stopping loss = 0.61, early stopping acc = 81.4 (0.719 sec)\n",
            "2024-11-27 20:55:05: Epoch 1140: Train loss = 0.24, train acc = 100.0, early stopping loss = 0.59, early stopping acc = 80.2 (0.723 sec)\n",
            "2024-11-27 20:55:06: Epoch 1160: Train loss = 0.22, train acc = 100.0, early stopping loss = 0.60, early stopping acc = 79.8 (0.723 sec)\n",
            "2024-11-27 20:55:07: Epoch 1180: Train loss = 0.24, train acc = 98.3, early stopping loss = 0.56, early stopping acc = 82.4 (0.725 sec)\n",
            "2024-11-27 20:55:07: Last epoch: 1196, best epoch: 1061 (77.123 sec)\n",
            "2024-11-27 20:55:08: Early stopping accuracy: 84.6%\n",
            "2024-11-27 20:55:08: Validation accuracy: 81.1%\n",
            "Training PPNP costs: 643.6594319343567 sec.\n",
            "/usr/local/lib/python3.10/dist-packages/scipy/sparse/_index.py:108: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            "Generating the new graph costs: 547.7846689224243 sec.\n",
            "2024-11-27 21:05:06: Fine-tuned model: {'hiddenunits': [64], 'drop_prob': 0.5, 'propagation': SDG()}\n",
            "2024-11-27 21:05:06: PyTorch seed: 2026734491\n",
            "2024-11-27 21:05:06: Epoch 0: Train loss = 0.24, train acc = 100.0, early stopping loss = 1.01, early stopping acc = 63.8 (0.062 sec)\n",
            "2024-11-27 21:05:13: Epoch 20: Train loss = 0.23, train acc = 98.3, early stopping loss = 0.63, early stopping acc = 78.4 (6.498 sec)\n",
            "2024-11-27 21:05:14: Epoch 40: Train loss = 0.23, train acc = 98.3, early stopping loss = 0.56, early stopping acc = 81.2 (0.723 sec)\n",
            "2024-11-27 21:05:14: Epoch 60: Train loss = 0.22, train acc = 100.0, early stopping loss = 0.59, early stopping acc = 79.0 (0.736 sec)\n",
            "2024-11-27 21:05:15: Epoch 80: Train loss = 0.21, train acc = 100.0, early stopping loss = 0.57, early stopping acc = 80.8 (0.775 sec)\n",
            "2024-11-27 21:05:16: Epoch 100: Train loss = 0.21, train acc = 100.0, early stopping loss = 0.60, early stopping acc = 78.2 (0.780 sec)\n",
            "2024-11-27 21:05:17: Epoch 120: Train loss = 0.24, train acc = 96.7, early stopping loss = 0.55, early stopping acc = 82.2 (0.780 sec)\n",
            "2024-11-27 21:05:18: Epoch 140: Train loss = 0.20, train acc = 100.0, early stopping loss = 0.59, early stopping acc = 79.4 (0.809 sec)\n",
            "2024-11-27 21:05:18: Epoch 160: Train loss = 0.22, train acc = 100.0, early stopping loss = 0.56, early stopping acc = 82.4 (0.725 sec)\n",
            "2024-11-27 21:05:19: Epoch 180: Train loss = 0.20, train acc = 100.0, early stopping loss = 0.58, early stopping acc = 79.2 (0.723 sec)\n",
            "2024-11-27 21:05:20: Epoch 200: Train loss = 0.22, train acc = 100.0, early stopping loss = 0.62, early stopping acc = 78.0 (0.727 sec)\n",
            "2024-11-27 21:05:20: Epoch 220: Train loss = 0.21, train acc = 100.0, early stopping loss = 0.56, early stopping acc = 81.8 (0.720 sec)\n",
            "2024-11-27 21:05:21: Epoch 240: Train loss = 0.19, train acc = 100.0, early stopping loss = 0.57, early stopping acc = 80.2 (0.722 sec)\n",
            "2024-11-27 21:05:22: Epoch 260: Train loss = 0.20, train acc = 100.0, early stopping loss = 0.57, early stopping acc = 81.0 (0.729 sec)\n",
            "2024-11-27 21:05:22: Last epoch: 266, best epoch: 13 (15.727 sec)\n",
            "2024-11-27 21:05:22: Early stopping accuracy: 84.4%\n",
            "2024-11-27 21:05:22: Validation accuracy: 81.7%\n",
            "Generating the new graph + Training SDG costs: 614.8045625686646 sec.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.Conclusion"
      ],
      "metadata": {
        "id": "LBpoSM8lYrFt"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f393VRCdVi8b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}